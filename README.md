# Machine Learning Engineer Nanodegree

The course focused on learning advanced machine learning techniques and algorithms and how to package and deploy models to a production environment. These, while gaining practical experience using Amazon SageMaker to deploy trained models to a web application and evaluate their performance. The following were the main three focuses:

## [Capstone Project](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/tree/master/Capstone)

Computer vision is the field of study that focuses on how to train computers to understand and interpret visual information such as images or videos. The resulting models have shown to be really useful for different applications such as self-driving cars, facial recognition, defect detection on production lines, and more. However, the training of these models usually requires massive amounts of data and the performance of the developed algorithms varies between different cases. The projects within the field of computer vision are often challenging as the benchmark for comparison is human vision, which is incredibly successful in performing these types of tasks.

The dog breed classification problem focuses on solving two main problems. First, the model is trained to recognize if the input image contains a human or a dog, and second, it identifies the breed that these resemble. It is a supervised multi-class classification problem that predicts among 133 types of dog breeds.

## [Deployment Tutorials](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/tree/master/Deployement%20Exercises)

This repository contains code and associated files for deploying ML models using AWS SageMaker. This repository consists of a number of tutorial notebooks for various coding exercises, mini-projects, and project files that will be used to supplement the lessons of the Nanodegree.

### Tutorials
* [Boston Housing (Batch Transform) - High Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Batch%20Transform)%20-%20High%20Level%20(1).ipynb) is the simplest notebook which introduces to the SageMaker ecosystem and how everything works together. The data used is already clean and tabular so that no additional processing needs to be done. Uses the Batch Transform method to test the fit model.
* [Boston Housing (Batch Transform) - Low Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Batch%20Transform)%20-%20Low%20Level.ipynb) performs the same analysis as the low level notebook, instead using the low level api. As a result it is a little more verbose, however, it has the advantage of being more flexible. It is a good idea to know each of the methods even if you only use one of them.
* [Boston Housing (Deploy) - High Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Deploy)%20-%20High%20Level.ipynb) is a variation on the Batch Transform notebook of the same name. Instead of using Batch Transform to test the model, it deploys and then sends the test data to the deployed endpoint.
* [Boston Housing (Deploy) - Low Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Deploy)%20-%20Low%20Level.ipynb) is again a variant of the Batch Transform notebook above. This time using the low level api and again deploys the model and sends the test data to it rather than using the batch transform method.
* [IMDB Sentiment Analysis - XGBoost - Web App](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20-%20Web%20App.ipynb) creates a sentiment analysis model using XGBoost and deploys the model to an endpoint. Then describes how to set up AWS Lambda and API Gateway to create a simple web app that interacts with the deployed endpoint.
* [Boston Housing (Hyperparameter Tuning) - High Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Hyperparameter%20Tuning)%20-%20High%20Level.ipynb) is an extension of the Boston Housing XGBoost model where instead of training a single model, the hyperparameter tuning functionality of SageMaker is used to train a number of different models, ultimately using the best performing model.
* [Boston Housing (Hyperparameter Tuning) - Low Level](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20XGBoost%20(Hyperparameter%20Tuning)%20-%20Low%20Level.ipynb) is a variation of the high level hyperparameter tuning notebook, this time using the low level api to create each of the objects involved in constructing a hyperparameter tuning job.
* [Boston Housing - Updating an Endpoint](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Tutorials/Boston%20Housing%20-%20Updating%20an%20Endpoint.ipynb) is another extension of the Boston Housing XGBoost model where in addition we construct a Linear model and switch a deployed endpoint between the two constructed models. In addition, we look at creating an endpoint which simulates performing an A/B test by sending some portion of the incoming inference requests to the XGBoost model and the rest to the Linear model.

### Mini-Projects
* [IMDB Sentiment Analysis - XGBoost (Batch Transform)](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Mini-projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Batch%20Transform).ipynb) is a notebook twhich leads  through the steps of constructing a model using XGBoost to perform sentiment analysis on the IMDB dataset.
* [IMDB Sentiment Analysis - XGBoost (Hyperparameter Tuning)](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Mini-projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Hyperparameter%20Tuning).ipynb) is a notebook  which leads you through the steps of constructing a sentiment analysis model using XGBoost and using SageMaker's hyperparameter tuning functionality to test a number of different hyperparameters.
* [IMDB Sentiment Analysis - XGBoost (Updating a Model)](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Mini-projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Updating%20a%20Model).ipynb) is a notebook which leads you through the steps of constructing a sentiment analysis model using XGBoost and then exploring what happens if something changes in the underlying distribution. After exploring a change in data over time you will construct an updated model and then update a deployed endpoint so that it makes use of the new model.

### Deployment Project

[Sentiment Analysis Web App](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Deployement%20Exercises/Sentiment%20Analysis%20Project/SageMaker%20Project.ipynb) The result is a deployed RNN performing sentiment analysis on movie reviews complete with publicly accessible API and a simple web page which interacts with the deployed endpoint.


## [Case Studies](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/tree/master/Case%20Studies)

* [Population Segmentation](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Case%20Studies/Population%20Segmentation/Pop_Segmentation_Exercise.ipynb): Learned how to build and deploy unsupervised models in SageMaker. In this example, I clustered US Census data; reducing the dimensionality of data using PCA and then clustering the resulting, top components with k-means.
* [Payment Fraud Detection](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Case%20Studies/Payment%20Fraud%20Detection/Fraud_Detection_Exercise.ipynb): Learned how to build and deploy a supervised, LinearLearner model in SageMaker. Tuned a model and handled a case of class imbalance to train a model to detect cases of credit card fraud.
* [Deploy a Custom PyTorch Model (Moon Data)](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Case%20Studies/Moon%20Data%20Classification/Moon_Classification_Exercise.ipynb): Trained and deployed a custom PyTorch neural network that classified "moon" data; binary data distributed in moon-like shapes.
* [Time Series Forecasting](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/blob/master/Case%20Studies/Time-series%20Forecasting/Energy_Consumption_Exercise.ipynb): Learned to analyze time series data and format it for training a [DeepAR](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) algorithm; a forecasting algorithm that utilizes a recurrent neural network. Train a model to predict household energy consumption patterns and evaluate the results.

### Case Study Project

[Plagiarism Detector](https://github.com/Omar-Martinez/Machine-Learning-Engineer-Nanodegree-/tree/master/Case%20Studies/Project%20Plagiarism%20Detector): Built an end-to-end plagiarism classification model. 
